{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification\n",
    "\n",
    "**Aim:** exercise with classification problems beyond binary classification. \n",
    "\n",
    "We will see two strategies to address the multi-class classification problem:\n",
    "- OvR: one versus the rest\n",
    "- OvO: one versus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# unit test utilities: you can ignore these function\n",
    "def is_approximately_equal(test,target,eps=1e-2):\n",
    "    return np.mean(np.fabs(np.array(test) - np.array(target)))<eps\n",
    "\n",
    "def assert_test_equality(test, target):\n",
    "    assert is_approximately_equal(test, target), 'Expected:\\n %s \\nbut got:\\n %s'%(target, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Implement the procedures `train_svm, test_svm, score_svm` to train, test and compute the distance from the boundary surface for a large margin linear binary classifier.\n",
    "\n",
    "Make the functions `estimator = train_svm(X_train, y_train, param)` and `test_svm(X_test, estimator)` and `score_svm(X_test, estimator)`. The function `train` takes in input a data matrix `X_train` a target vector `y_train` and a single value `param` which specifies the regularization constat `C`. The function `train_svm` outputs an estimator object. The function of type `test_svm` takes in input a data matrix `X_test` the fit object `estimator` and outputs the predicted targets. The function `score_svm` takes in input a data matrix `X_test` the fit object `estimator` and outputs the distance from the boundary surface for each instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_svm(X_train, y_train, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def test_svm(X_test, est):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def score_svm(X_test, est):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvR\n",
    "\n",
    "The one-vs-rest strategy, also known as one-vs-all, consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. \n",
    "\n",
    "Advantages:\n",
    "- it is computational efficiency as only n_classes classifiers are needed\n",
    "- it is interpretabile as each class is represented by one and only one classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Implement the function `estimators = train_OvR(X_train, y_train, train_func, param)` and the function `preds = test_OvR(X_test, score_func, estimators)`. \n",
    "\n",
    "`train_OvR` takes in input the data matrix `X_train`, the target vector `y_train`, the training procedure `train_func` with an associated parameter `param` and it outputs an object that represent the estimators fit using the OvR strategy.\n",
    "\n",
    "`test_OvR` takes in input the data matrix `X_test`, the scoring procedure `score_func`, the estimators object and it returns the predicted class for each instance in the data matrix.\n",
    "\n",
    "*Note that here we need to employ a scoring procedure and not a classification procedure, as we need to find the most confident estimate for each prediction.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_OvR(X_train, y_train, train_func, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def test_OvR(X_test, score_func, estimator):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. \n",
    "### BEGIN TESTS \n",
    "X_train = np.array([[10, 10],[8, 10],[-5, 5.5],[-5.4, 5.5],[-20, -20],[-15, -20]])\n",
    "y_train = np.array([0, 0, 1, 1, 2, 2])\n",
    "X_test = np.array([[-19, -20], [9, 9], [-5, 5]])\n",
    "y_test = np.array([2, 0, 1])\n",
    "est = train_OvR(X_train, y_train, train_svm, param=1)\n",
    "preds = test_OvR(X_test, score_svm, est)\n",
    "test_cm = confusion_matrix(y_test, preds)\n",
    "target_cm = np.eye(3)\n",
    "assert_test_equality(target_cm, test_cm)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvO\n",
    "\n",
    "The one-vs-one strategy constructs one classifier per pair of classes. At prediction time, the class which received the most votes is selected. \n",
    "\n",
    "In the event of a tie (among two classes with an equal number of votes), it selects the class with the highest aggregate classification confidence by summing over the pair-wise classification confidence levels computed by the underlying binary classifiers.\n",
    "In this exercise you can ignore this case and break the tie at random.\n",
    "\n",
    "Cons:\n",
    "- complexity: it requires to fit n_classes * (n_classes - 1) / 2 classifiers\n",
    "\n",
    "Pros:\n",
    "- smaller individual problems: each individual learning problem only involves a small subset of the data whereas in OvR the complete dataset is used n_classes times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Implement the function `estimators = train_OvO(X_train, y_train, train_func, param)` and the function `preds = test_OvO(X_test, test_func, estimators)`. \n",
    "\n",
    "`train_OvO` takes in input the data matrix `X_train`, the target vector `y_train`, the training procedure `train_func` with an associated parameter `param` and it outputs an object that represent the estimators fit using the OvR strategy.\n",
    "\n",
    "`test_OvO` takes in input the data matrix `X_test`, the scoring procedure `test_func`, the estimators object and it returns the predicted class for each instance in the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_OvO(X_train, y_train, train_func, param):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def test_OvO(X_test, test_func, estimators):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is reserved for the unit tests. Do not consider this cell. \n",
    "### BEGIN TESTS \n",
    "X_train = np.array([[10, 10],[8, 10],[-5, 5.5],[-5.4, 5.5],[-20, -20],[-15, -20]])\n",
    "y_train = np.array([0, 0, 1, 1, 2, 2])\n",
    "X_test = np.array([[11, 11], [-5, 5], [-15, -15]])\n",
    "y_test = np.array([0, 1, 2])\n",
    "est = train_OvO(X_train, y_train, train_svm, param=1)\n",
    "preds = test_OvO(X_test, test_svm, est)\n",
    "test_cm = confusion_matrix(y_test, preds)\n",
    "target_cm = np.eye(3)\n",
    "assert_test_equality(target_cm, test_cm)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Apply the OvR and OvO technique on the [digit dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html?highlight=digits#sklearn.datasets.load_digits).\n",
    "\n",
    "Compare your results with the implementation offered by *scikit*.\n",
    "\n",
    "You just need to run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = train_OvR(X_train, y_train, train_svm, param=1)\n",
    "preds = test_OvR(X_test, score_svm, est)\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "preds = OneVsRestClassifier(LinearSVC(C=1)).fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = train_OvO(X_train, y_train, train_svm, param=1)\n",
    "preds = test_OvO(X_test, test_svm, est)\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "preds = OneVsOneClassifier(LinearSVC(C=1)).fit(X_train, y_train).predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
